\documentclass[a4paper]{article}
% \usepackage[margin=1.5in]{geometry}
\usepackage{fontspec}
\usepackage{csquotes}
\usepackage[hidelinks]{hyperref}
\usepackage[backend=biber, style=alphabetic]{biblatex}
\usepackage{lastpage}
\usepackage{xspace}
\usepackage{paralist}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{mathtools}
\usepackage{lipsum}
\usepackage[svgnames]{xcolor}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{listings}

\makeatletter
\renewcommand{\@evenfoot}{\hfil \thepage{} of \pageref*{LastPage}\hfil}
\renewcommand{\@oddfoot}{\@evenfoot}
\makeatother

\newcommand{\tname}[1]{\textsc{#1}\xspace}
\newcommand{\etcd}{\tname{etcd}}

\newcommand*{\eg}{e.g.\@\xspace}
\newcommand*{\ie}{i.e.\@\xspace}

\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}

\bibliography{references}

\title{CS6213 Project Report}
\author{George PÃ®rlea \and Darius Foo}
\date{\today}

\begin{document}

\maketitle

\section{Motivation}

Writing a formal specification of a system is useful in clarifying details of its design.
%
As the system evolves, however, it is difficult to ensure that its implementation and specification have not diverged.

In this work, we investigate lightweight (an engineer can learn and produce something useful in 2-3 weeks~\cite{newcombe_how_2015}) but systematic methods to check that a system implementation conforms to its specification.

\section{Scope}

We set out to answer the following research questions:

\begin{enumerate}[label={(Q\arabic*)}]
    \item \textbf{Conformance testing.} Given a TLA model that satisfies some simple properties and a system implementation, what is the easiest way to check that the implementation satisfies the properties?

    \item \textbf{Refinement mappings.} Given a model and an implementation, how can we best define the correspondence between the two, perhaps via a combination of manual/inferred annotations?

    \item \textbf{Empirical evaluation of conformance.} For real-world distributed systems that come with both TLA models and implementations, empirically, is there a correspondence between the model and the implementation?
\end{enumerate}

Our original intention was to select three open-source implementations of the Raft consensus protocol~\cite{ongaro_search_2014, ongaro_consensus_2014} and evaluate to what extent they match the behaviour of the TLA specification written by Diego Ongaro.

Due to time constraints, we had to reduce our ambitions.
%
In the end, we evaluated only the most widely used implementation, \etcd, and not to the extent we had initially hoped.
%
Nonetheless, our experience has been instructive and leads us to believe there is potential in continuing this line of work.

\section{Project Summary}

\begin{itemize}
    \item We combined three existing TLA specifications (due to Diego Ongaro, Daniel Ricketts, and Brandon Amos and Hangcheng Zhang) into a reference specification of Raft with one-at-a-time membership changes.

    \item We started developing a prototype testing framework on top of \etcd to simulate execution traces generated by TLC.

    \item We noticed that model checking performance is low.
    %
    With the default TLC configuration, on a model with 3 nodes, it took 2 minutes before the first entry was added to a log, when running TLC on our laptops.
    %
    Entries began to be committed only much later.

    \item Hoping for a better model checking experience, we adapted our specification for use with the Apalache symbolic model checker.
    %
    This required adding type annotations to the TLA specification and slightly rewriting some operators to fit into the subset of TLA that can be automatically translated to SMT.
    %
    Apalache is alpha software, so we ran into a large number of bugs.
    %
    Sadly, for our specification, Apalache symbolic model checking was orders of magnitude slower than TLC.

    \item Disappointed with Apalache's performance, we reverted to using TLC to generate Raft execution traces.
    
    \item We investigated approaches to constrain TLC's search space (state constraints, symmetry, action constraints, and views).
    %
    We also explored different search strategies (depth first search, simulation mode), but these were unhelpful.
    %
    Put together, the various approaches offered a 2-3 orders of magnitude performance improvement for our use-case of generating test traces.
    % 
    But even this was not enough to generate traces for all the scenarios we wanted to test, some of which required traces 30 steps long.

    \item We discovered that, for trace generation (as opposed to model checking), certain properties allow for a specialised search strategy reminiscent of concolic execution: a burst of breadth-first search, followed by focusing on a single trace (and its final state), followed by another breadth-first search starting from \emph{that} state.
    %
    We used this strategy, which we ``implemented'' manually using TLC state constraints, to obtain very deep Raft traces, \eg, a period with two concurrent leaders during which an entry commits, followed by a majority of the cluster restarting.

    \item In the process, we discovered (low impact) errors in the
    specification of membership changes due to Amos and Zhang and in the
    properties stated by Daniel Ricketts.
    %
    This suggests that their specifications have been model-checked only to a shallow extent.
    %
    Given the effort we spent to obtain reasonable performance out of TLC, this is understandable.

\end{itemize}


\section{Approach}

\subsection{Model-based Test Case Generation (MBTCG)}
\label{sec: interpreter}

The MBTCG approach uses a specification to guide the generation of test cases for the implementation.

The specification is typically given in the form of a transition system (consisting of states and \emph{actions} which give rise to transitions between states) and its invariants.
%
A model checker may then be used to output sequences of states (or \emph{traces}) which violate the invariants.
%
Such traces may equivalently be seen as sequences of actions, starting and ending at particular states.

The idea is to feed a trace into the implementation and check if the implementation also arrives at the ``same'' final state. Used this way, a trace serves as a test case.
%
To do that, the implementation must be extended with

\begin{enumerate}
    \item An abstraction function, mapping an implementation state to a specification state.

    \item An interpreter for actions. This may be seen as a concretization function, mapping a specification action to an implementation state change.
\end{enumerate}

There are a number of challenges to doing this.

\begin{itemize}
\item \textbf{Concurrency.} The interpreter has to drive the implementation forward in such a way that each intermediate state corresponds to a linearization point.
%
There is otherwise no guarantee that any observed implementation state matches some specification state.
%
To ensure this, the interpreter is synchronised, e.g. waiting for a message to appear in the soup as confirmation that an action has been executed.
%
At that point we know that the system is relatively quiescent and can observe its state.

\item \textbf{Modifications.} Implementing the interpreter might require changes to the implementation which interfere with its integrity: to what extent is the modified implementation representative of the program we want to check the conformance of?
%
This is of particular concern when the interpreter is retroactively added to an implementation, as we are doing; ideally, the implementation would natively support interpreting actions.
%
We try to minimise our changes and limit them to events that may be externally controlled, e.g. timeouts and message sends and receives, and implement only what is necessary to expose external control of such events.

% this whole section could probably be explained better, with an example

\item \textbf{Nondeterminism.} Nondeterministic specification actions typically correspond to some composition of implementation actions with a deterministic prefix.
%
For example, a specification action might allow a message to be sent when a variable has a certain value; an implementation is likely to send this message upon the variable's value changing as part of an earlier action.
%
Decoupling these actions in the implementation is not always possible (if determinism is required) or desirable (if it would be a nontrivial implementation change).
%
Not decoupling them would risk the linearization point being misplaced, but we choose this option instead, with a number of mitigating measures:

\begin{enumerate}
\item The specification could be rewritten to remove nondeterminism, so that actions have a deterministic prefix.
%
This is always possible because sequences of actions generated by the model checker can be reordered if the actions commute, and if the specification actions corresponding to the composed implementation transition are the only ones modifying some particular part of the state, they would commute with all intervening ones and could be reordered and fused \cite{lipton1975reduction}.

\item The abstraction function could be used to remove state which would cause the linearization point to be misplaced.
\end{enumerate}

\end{itemize}

\subsection{\etcd}

We chose \etcd\footnote{\url{https://etcd.io/}}, a distributed key-value store, for our experiments.
%
It is notable for being the most widely-used Raft implementation in production\footnote{\url{https://github.com/etcd-io/etcd/blob/master/raft/README.md}}, implementing many of the extensions described in Ongaro's thesis \cite{ongaro_consensus_2014}, including multiple-at-a-time membership changes with joint consensus as well as PreVote and CheckQuorum~\cite{howard_raft_2020}.
%
It also has a comprehensive test suite utilising fault injection\footnote{\url{https://github.com/etcd-io/etcd/blob/master/tests/functional/README.md}}.
%
This made it ideal for testing our hypotheses that (1) widely-used implementations could have deep protocol bugs which (2) fault injection would not be able to find.

\etcd's Raft implementation is highly modular: it is structured as a state machine whose inputs are messages, with storage and transport left abstract, for users to provide.
%
The user also provides an event loop to drive the state machine.

We extended the demo application that \etcd provides and implemented an interpreter following the general ideas in Section~\ref{sec: interpreter}.

The state of the interpreter is a cluster of Raft nodes, modelled using goroutines and thus running in the same process (but only communicating via messages).
%
We implemented a custom transport layer which uses in-memory Go channels, and use \etcd's built-in in-memory storage for snapshots, and disk storage for the write-ahead log, which we modified to be more resilient to race conditions around \etcd's implementation of \texttt{flock}.
%
We also implemented a custom per-node clock which is advanced by interpreter actions instead of real time.

The interpreter takes as input a trace in JSON format, produced by running \texttt{tla2json}\footnote{\url{https://github.com/japgolly/tla2json}} on the output of the TLC model checker, then executes each action in sequence, blocking until it is complete.
%
In between executing actions, assuming we are at a linearization point, we output the state of the interpreter by applying the abstraction function to the in-memory state of the cluster.
%
The final state it reaches is compared with the last state in the input trace to determine if the implementation behaves the same way as the specification.

The entire process in action can be seen in the output in Figure~\ref{fig:output} (with some nonessential lines removed).
%
The lines beginning with dates are logging from \etcd itself, which we did not modify.
%
Those beginning with --- are linearization points at which we observe the state (not shown) before executing the \emph{next} interpreter action, whose arguments make up the rest of each line.
%
The first action makes node 1 time out, which causes it to begin a new election in the following line.
%
This is followed by a flurry of sends and receives.
%
Notably, because the interpreter and the cluster are running concurrently, and because the implementation is deterministic, messages are sent in the implementation (\texttt{MsgVote}) before the corresponding actions are executed by the interpreter.
%
This is an example of nondeterministic specification actions having some deterministic prefix in the implementation.
%
Fortunately, this does not cause a problem, as the custom transport intercepts and holds the \texttt{MsgVote} message (conceptually, retaining it in the message soup), and it only the subsequent send of \texttt{RequestVoteReq} (the specification equivalent of \texttt{MsgVote}) that causes it to be released and actually delivered to its destination.

The remainder of the output shows the effect of Raft's \texttt{RequestVote} messages, which cause votes to be cast and term numbers to be updated.
%
It concludes with node 1 becoming leader, and only stops \emph{after} a leader has been elected, as that is the synchronisation condition that the \texttt{BecomeLeader} action provides.
%
The final state of the implementation and specification are then output.

Interestingly, the leader ends up with a single entry in its log with value 0, despite no client requests occurring.
%
This is \etcd's realisation of the approach from Section~5.2 of the original paper \cite{ongaro_search_2014}: ``Once a candidate wins an election, it becomes leader.
%
It then sends heartbeat messages to all of the other servers to establish its authority and prevent new elections.'' This particular implementation of Raft has newly-elected leaders add an empty entry (represented abstractly by the value 0) to their own logs, which triggers replication via \texttt{AppendEntries} that causes other candidates to step down.
%
This is one of a number of details we only discovered using our approach and had to extend the specification with.
%
The trace then ends, before the leader replicates these log entries.

\begin{figure}
% \newgeometry{left=0.2cm,bottom=0.1cm}
\centering
\begin{lstlisting}[breaklines=true,basicstyle=\ttfamily]
2021/05/07 15:45:01 replaying WAL of member 1
raft2021/05/07 15:45:02 INFO: 1 became follower at term 1
2021/05/07 15:45:02 replaying WAL of member 2
raft2021/05/07 15:45:02 INFO: 2 became follower at term 1
2021/05/07 15:45:02 replaying WAL of member 3
raft2021/05/07 15:45:02 INFO: 3 became follower at term 1
----{Type:Timeout Message:{Type:RequestVoteReq Entries:[]} Sender:0 Recipient:1}
raft2021/05/07 15:45:02 INFO: 1 is starting a new election at term 1
raft2021/05/07 15:45:02 INFO: 1 became candidate at term 2
raft2021/05/07 15:45:02 INFO: 1 received MsgVoteResp from 1 at term 2
raft2021/05/07 15:45:02 INFO: 1 [logterm: 1, index: 3] sent MsgVote request to 2 at term 2
raft2021/05/07 15:45:02 INFO: 1 [logterm: 1, index: 3] sent MsgVote request to 3 at term 2
----{Type:Send Message:{Type:RequestVoteReq Entries:[]} Sender:1 Recipient:2}
----{Type:Receive Message:{Type:RequestVoteReq Entries:[]} Sender:1 Recipient:2}
----{Type:Send Message:{Type:RequestVoteRes Entries:[]} Sender:2 Recipient:1}
raft2021/05/07 15:45:02 INFO: 2 [term: 1] received a MsgVote message with higher term from 1 [term: 2]
raft2021/05/07 15:45:02 INFO: 2 became follower at term 2
raft2021/05/07 15:45:02 INFO: 2 [logterm: 1, index: 3, vote: 0] cast MsgVote for 1 [logterm: 1, index: 3] at term 2
----{Type:Receive Message:{Type:RequestVoteRes Entries:[]} Sender:2 Recipient:1}
----{Type:BecomeLeader Message:{Type:RequestVoteReq Entries:[]} Sender:0 Recipient:1}
raft2021/05/07 15:45:02 INFO: 1 received MsgVoteResp from 2 at term 2
raft2021/05/07 15:45:02 INFO: 1 has received 2 MsgVoteResp votes and 0 vote rejections
raft2021/05/07 15:45:02 INFO: 1 became leader at term 2
raft2021/05/07 15:45:02 INFO: raft.node: 1 elected leader 1 at term 2
----Finished
spec state: { atLeastOneLeader: true, logs: { 1: [{ term: 2, type: ValueEntry, value: 0 }], 2: [], 3: [] } }

impl state: { atLeastOneLeader: true, logs: { 1: [{ term: 2, type: ValueEntry, value: 0 }], 2: [], 3: [] } }
\end{lstlisting}
% \restoregeometry
\label{fig:output}
\caption{Interpreter output for trace generated using \texttt{BecomeLeader} invariant}
\end{figure}

There are three outcomes to an interpreter run: it either terminates with matching or non-matching specification and implementation state, or does not terminate.
%
The non-matching and nonterminating outcomes are caused by the state of the implementation diverging from the abstract state of the specification, at which point all bets are off, and actions no longer make sense, e.g.~waiting for the wrong kind of message, which never arrives.

The specification and implementation mismatches indicated by such outcomes are typically caused by implementation behaviour that is not modelled in the specification, or bugs in either one; either way, these are the outcomes we were looking for further scrutinise.

\begin{itemize}
\item The specification did not cover the extra log entry leaders use to suppress competing elections
\item The specification did not cover empty \texttt{AppendEntries} leaders may send up-to-date followers upon committing entries, to get them to advance their commit index
\end{itemize}

We did not find any bugs in the implementation, only specification omissions.

We ran a total of 6 traces generated by the same number of invariants, covering scenarios of increasing complexity, e.g.~first a single leader, then two leaders concurrently, then a commit in the presence of two leaders.
%
Supporting each kind of trace required identifying implementation analogues (usually a method call) as well as synchronisation conditions for each specification action.
%
Some specification actions had no implementation counterpart in the parts of the implementation we had control over (the soup), e.g.~a leader voting for itself; in cases like these we only implementation synchronisation conditions.

In total we added support for 7 specification actions (\texttt{Timeout}, \texttt{Send}, \texttt{Receive}, \texttt{BecomeLeader}, \texttt{Restart}, \texttt{TryRemoveServer}, \texttt{RemoveServer}) and 4 messages (\texttt{RequestVote} and \texttt{AppendEntries} requests and responses).

We implemented a number of modifications to \etcd's Raft library to make this possible.
%
These are distinguished from the modifications above as they are not merely scaffolding for the interpreter, but are changes to the internals of the library, i.e.
%
they may compromise the integrity of the implementation.
%
We ensured that all of these were trivial (exposing private fields, returning derived state) to minimise the risk of compromising the implementation's integrity.

\subsection{Takeaways}

We believe that our model-based testing approach is promising as it allows us to link specification to implementation, taking advantage of the redundancy to identify discrepancies \cite{fonseca2017empirical}.
%
The changes to the implementation are not invasive, e.g.~it is not required that it be reimplemented in a different language, merely that the interpreter is additionally implemented.

The main deterrent is the amount of engineering effort required \cite{Davis_2020}, as it is fundamentally not a black box approach -- the internals of the implementation must be carefully reflected in the specification.
%
This is of less concern for greenfield projects designed with this approach in mind (e.g.~supporting the execution of high-level actions), but retrofitting an interpreter onto a mature application can be a significant endeavour, as there are a multitude of details in such a scenario which will not appear in the specification, and must be added.

Furthermore, it is not enough that the specification describes the essence of the implementation; it must be \emph{expressed} in such a way that the correspondence with the implementation is straightforward.

% \renewcommand*{\bibfont}{\footnotesize}
\printbibliography

\end{document}
